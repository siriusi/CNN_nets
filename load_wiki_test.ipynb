{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import sys\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_margin(img, face_loc):\n",
    "    crop_h = int(0.4 * (face_loc[3] - face_loc[1]))\n",
    "    crop_w = int(0.4 * (face_loc[2] - face_loc[0]))\n",
    "    img_h = img.shape[0]\n",
    "    img_w = img.shape[1]\n",
    "    #new_crop_low = crop_h + face_loc[1] - crop_h\n",
    "    new_crop_high = crop_h + face_loc[3] + crop_h\n",
    "    #new_crop_left = crop_w + face_loc[0] - crop_w\n",
    "    new_crop_right = crop_w + face_loc[2] + crop_w\n",
    "    replicate = cv2.copyMakeBorder(img, crop_h, crop_h, crop_w, crop_w, cv2.BORDER_REPLICATE)\n",
    "    crop_face_img = replicate[face_loc[1] : new_crop_high, face_loc[0] : new_crop_right]\n",
    "    return crop_face_img\n",
    "\n",
    "#产生新图像\n",
    "def add_augment_img(img):\n",
    "    translateX = np.random.uniform(-0.1, 0.1)\n",
    "    translateY = np.random.uniform(-0.1, 0.1)\n",
    "    scale = np.random.uniform(0.9, 1.1)\n",
    "    rotate_angle = np.random.uniform(-10, 10)\n",
    "    \n",
    "    def translate(image, x, y):\n",
    "        # 定义平移矩阵\n",
    "        M = np.float32([[1, 0, x], [0, 1, y]])\n",
    "        shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "        # 返回转换后的图像\n",
    "        return shifted\n",
    "    \n",
    "    # 定义旋转rotate函数\n",
    "    def rotate(image, angle, center=None, scale=1.0):\n",
    "        # 获取图像尺寸\n",
    "        (h, w) = image.shape[:2]\n",
    "\n",
    "        # 若未指定旋转中心，则将图像中心设为旋转中心\n",
    "        if center is None:\n",
    "            center = (w / 2, h / 2)\n",
    "\n",
    "        # 执行旋转\n",
    "        M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "        rotated = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "        # 返回旋转后的图像\n",
    "        return rotated\n",
    "    \n",
    "    img = translate(img, translateX, translateY)\n",
    "    \n",
    "    rotated = rotate(img, rotate_angle, scale = scale)\n",
    "    \n",
    "    return rotated\n",
    "\n",
    "    \n",
    "def load_wiki(wiki_path, num_data = None, target_size = (224,224)):\n",
    "    mat_path = wiki_path + 'wiki_with_age.mat'\n",
    "    \n",
    "    data = sio.loadmat(mat_path)\n",
    "    wiki_data = data['wiki'][0][0]\n",
    "   \n",
    "    num_full_data = len(wiki_data[6][0])\n",
    "    if num_data is None:\n",
    "        num_data = num_full_data\n",
    "        \n",
    "    \n",
    "    X_data_age = np.zeros([num_data, 224, 224, 3],dtype = \"uint8\")\n",
    "    y_data_age = np.zeros([num_data],dtype = \"uint8\")\n",
    "    \n",
    "    X_data_gender = np.zeros([num_data, 224, 224, 3],dtype = \"uint8\")\n",
    "    y_data_gender = np.zeros([num_data],dtype = \"uint8\")\n",
    "    \n",
    "    full_X_data = np.zeros([num_data, 224, 224, 3], dtype = \"uint8\")\n",
    "    \n",
    "    data_count = 0\n",
    "    #len(wiki_data[6][0])\n",
    "    num_every_age = int(num_data / 100)\n",
    "    counter_every_age = np.zeros(100, np.int32)\n",
    "    index_every_age = np.zeros([100, num_every_age], np.int32)\n",
    "    \n",
    "    num_every_gender = int(num_data / 2)\n",
    "    counter_every_gender = np.zeros(2, np.int32)\n",
    "    index_every_gender = np.zeros([2, num_every_gender], np.int32)\n",
    "    i = 0\n",
    "    while i < num_full_data and data_count < num_data:\n",
    "        \n",
    "        face_score =wiki_data[6][0][i]\n",
    "        if face_score != float(\"-inf\"):         #如果face_score == -inf说明不存在脸,这个比例比较大，因此先排除\n",
    "            full_path = wiki_path + wiki_data[2][0][i][0]\n",
    "            img = cv2.imread(full_path)\n",
    "            age = int(wiki_data[8][0][i])            #有些age在正常值之外要排除\n",
    "            date_of_birth = wiki_data[0][0][i]  #下面的657438是出生于1800年的Matlab serial date number\n",
    "            gender = wiki_data[3][0][i]        #有一些gender==None会引起一场，需要排除\n",
    "            if img is not None and gender == gender and date_of_birth > 657438 and age >= 0 and age < 100:\n",
    "                gender = int(gender)  \n",
    "                face_loc = wiki_data[5][0][i][0]\n",
    "                face_loc = face_loc.astype(\"int32\")\n",
    "                roi_img = add_margin(img, face_loc)    \n",
    "                face_img = cv2.resize(roi_img, target_size)\n",
    "                \n",
    "                \n",
    "                if counter_every_age[age] < num_every_age: \n",
    "                    index_every_age[age, counter_every_age[age]] = data_count\n",
    "                    counter_every_age[age] = counter_every_age[age] + 1\n",
    "                \n",
    "                if counter_every_gender[gender] < num_every_gender: \n",
    "                    index_every_gender[gender, counter_every_gender[gender]] = data_count\n",
    "                    counter_every_gender[gender] = counter_every_gender[gender] + 1\n",
    "                \n",
    "                full_X_data[data_count] = face_img                \n",
    "               \n",
    "                data_count = data_count + 1\n",
    "        i = i + 1\n",
    "                \n",
    "    for cur_age in range(100):            \n",
    "        cur_age_start_index = cur_age * num_every_age\n",
    "        X_data_age[cur_age_start_index : cur_age_start_index + num_every_age] \\\n",
    "                        = full_X_data[index_every_age[cur_age]]\n",
    "        assert counter_every_age[cur_age] > 0, \"年龄\"+ str(cur_age) +\"没有数据\"\n",
    "        if counter_every_age[cur_age] < num_every_age and counter_every_age[cur_age] > 0:\n",
    "            for cur_augment in range(num_every_age - counter_every_age[cur_age]):\n",
    "                cur_choice = np.random.choice(index_every_age[cur_age], replace = False)\n",
    "                X_data_age[cur_age_start_index + counter_every_age[cur_age] + cur_augment] \\\n",
    "                                = add_augment_img(full_X_data[cur_choice])\n",
    "        y_data_age[cur_age_start_index : cur_age_start_index + num_every_age] = cur_age\n",
    "        \n",
    "    for cur_gender in range(2):            \n",
    "        cur_gender_start_index = cur_gender * num_every_gender\n",
    "        X_data_gender[cur_gender_start_index : cur_gender_start_index + num_every_gender] \\\n",
    "                        = full_X_data[index_every_gender[cur_gender]]\n",
    "        assert counter_every_gender[cur_gender] > 0, \"性别\"+ str(cur_gender) +\"没有数据\"\n",
    "        if counter_every_gender[cur_gender] < num_every_gender:\n",
    "            for cur_augment in range(num_every_gender - counter_every_gender[cur_gender]):\n",
    "                cur_choice = np.random.choice(index_every_gender[cur_gender], replace = False)\n",
    "                X_data_gender[cur_gender_start_index + counter_every_gender[cur_gender] + cur_augment] \\\n",
    "                                = add_augment_img(full_X_data[cur_choice])\n",
    "        y_data_gender[cur_gender_start_index : cur_gender_start_index + num_every_gender] = cur_gender\n",
    "    \n",
    "    \n",
    "    return X_data_age, y_data_age, X_data_gender, y_data_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_wiki_data(X_data, y_data, num_training=49000, num_validation=1000, num_test=1000, subtract_mean = True):\n",
    "   \n",
    "    X_train = X_data[:-(num_validation + num_test)]\n",
    "    y_train = y_data[:-(num_validation + num_test)]\n",
    "    X_val = X_data[X_train.shape[0] : -num_test]\n",
    "    y_val = y_data[X_train.shape[0] : -num_test]\n",
    "    X_test = X_data[-num_test:]\n",
    "    y_test = y_data[-num_test:]\n",
    "    # Normalize the data: subtract the mean image\n",
    "    if subtract_mean:\n",
    "        mean_image = np.mean(X_data, axis=0).astype(\"uint8\")\n",
    "        X_train -= mean_image\n",
    "        X_val -= mean_image\n",
    "        X_test -= mean_image\n",
    "    # Transpose so that channels come first\n",
    "    X_train = X_train.transpose(0, 3, 1, 2).copy()\n",
    "    X_val = X_val.transpose(0, 3, 1, 2).copy()\n",
    "    X_test = X_test.transpose(0, 3, 1, 2).copy()\n",
    "\n",
    "    # Package data into a dictionary\n",
    "    return {\n",
    "      'X_train': X_train, 'y_train': y_train,\n",
    "      'X_val': X_val, 'y_val': y_val,\n",
    "      'X_test': X_test, 'y_test': y_test,\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "年龄1没有数据",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-1f9620a65476>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmat_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwiki_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'wiki_with_age.mat'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mX_data_age\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data_age\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_data_gender\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data_gender\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mload_wiki\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwiki_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X_data_age \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_data_age\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-9f8ee40f4afc>\u001b[0m in \u001b[0;36mload_wiki\u001b[1;34m(wiki_path, num_data, target_size)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mcur_age_start_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur_age\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_every_age\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mX_data_age\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcur_age_start_index\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mcur_age_start_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnum_every_age\u001b[0m\u001b[1;33m]\u001b[0m                         \u001b[1;33m=\u001b[0m \u001b[0mfull_X_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex_every_age\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcur_age\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mcounter_every_age\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcur_age\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"年龄\"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_age\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\"没有数据\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcounter_every_age\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcur_age\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mnum_every_age\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcounter_every_age\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcur_age\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcur_augment\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_every_age\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcounter_every_age\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcur_age\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 年龄1没有数据"
     ]
    }
   ],
   "source": [
    "#不带h5py的\n",
    "wiki_path = \"\"\n",
    "if sys.platform == \"linux\" :\n",
    "    wiki_path = \"/devdata/wiki/\"\n",
    "else:\n",
    "    #wiki_path = \"G:\\\\MachineLearning\\\\wiki\\\\wiki\\\\\"\n",
    "    wiki_path = \"D:\\\\Z\\\\wiki\\\\\"\n",
    "\n",
    "mat_path = wiki_path + 'wiki_with_age.mat'\n",
    "\n",
    "X_data_age, y_data_age, X_data_gender, y_data_gender   = load_wiki(wiki_path, 2000)\n",
    "\n",
    "print(\"X_data_age \", X_data_age.shape)\n",
    "print(\"y_data_age \", y_data_age.shape)\n",
    "print(\"X_data_gender \", X_data_gender.shape)\n",
    "print(\"y_data_gender \", y_data_gender.shape)\n",
    "\n",
    "print(\"male: \", np.count_nonzero(y_data_gender - np.ones(2000,dtype = \"uint8\")))\n",
    "print(\"female: \", np.count_nonzero(y_data_gender - np.zeros(2000,dtype = \"uint8\")))\n",
    "      \n",
    "print(\"0: \", np.count_nonzero(y_data_age - np.zeros(2000,dtype = \"uint8\")))\n",
    "print(\"25: \", np.count_nonzero(y_data_age - (np.zeros(2000,dtype = \"uint8\") + 25)))\n",
    "print(\"50: \", np.count_nonzero(y_data_age - (np.zeros(2000,dtype = \"uint8\") + 50)))\n",
    "print(\"99: \", np.count_nonzero(y_data_age - (np.zeros(2000,dtype = \"uint8\") + 99)))\n",
    "      \n",
    "print(y_data_age)\n",
    "#wiki_cropface_dataset = get_wiki_data(X_data, y_data, num_training=49000, num_validation=10, num_test=0)\n",
    "index = 130\n",
    "cv2.imshow(\"gender_test\", X_data_gender[index])\n",
    "print(y_data_gender[index])\n",
    "      \n",
    "cv2.imshow(\"age_test\", X_data_age[index])\n",
    "print(y_data_age[index])\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h5py' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b547079a1c09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0my_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwiki_cropface_group\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"y_data\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/devdata/wiki_cropface_data.h5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mX_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mload_wiki\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwiki_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mwiki_cropface_group\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"wiki_cropface_group\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'h5py' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "wiki_path = \"\"\n",
    "if sys.platform == \"linux\" :\n",
    "    wiki_path = \"/devdata/wiki/\"\n",
    "else:\n",
    "    wiki_path = \"G:\\\\MachineLearning\\\\wiki\\\\wiki\\\\\"\n",
    "\n",
    "mat_path = wiki_path + 'wiki_with_age.mat'\n",
    "\n",
    "# Create a new file\n",
    "f = None\n",
    "X_data = None\n",
    "y_data = None\n",
    "#wiki_crop_dataset = f.create_dataset('wiki_cropface_data', dtype = \"int32\")\n",
    "if os.path.exists('/devdata/wiki_cropface_data.h5'):\n",
    "    f = h5py.File('/devdata/wiki_cropface_data.h5', \"r\")\n",
    "    wiki_cropface_group = f[\"wiki_cropface_group\"]\n",
    "    X_data = np.array(wiki_cropface_group[\"X_data\"][:])\n",
    "    y_data = np.array(wiki_cropface_group[\"y_data\"][:])\n",
    "else:\n",
    "    f = h5py.File('/devdata/wiki_cropface_data.h5',\"w\")\n",
    "    X_data, y_data  = load_wiki(wiki_path, 1)\n",
    "    wiki_cropface_group = f.create_group(\"wiki_cropface_group\")\n",
    "    wiki_cropface_group.create_dataset('X_data', dtype = \"uint8\", data = X_data)\n",
    "    wiki_cropface_group.create_dataset('y_data', dtype = \"uint8\", data = y_data)\n",
    "    \n",
    "print(X_data.shape)\n",
    "wiki_cropface_dataset = get_wiki_data(X_data, y_data, num_training=49000, num_validation=10, num_test=0)\n",
    "f.close()\n",
    "\"\"\"\n",
    "test_img = X_data[0,:,:,:]\n",
    "cv2.imshow(\"test_img\", test_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
